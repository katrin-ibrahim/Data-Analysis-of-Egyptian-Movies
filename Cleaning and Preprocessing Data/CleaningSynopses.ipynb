{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import qalsadi.lemmatizer\n",
    "import nltk\n",
    "from camel_tools.utils.dediac import dediac_ar\n",
    "from camel_tools.tokenizers.word import simple_word_tokenize\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel(r'E:\\DataAnalysis Internship\\cima.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesNames=data.get('اسم الفيلم')\n",
    "date=data.get('تاريخ العرض')\n",
    "categories=data.get('تصنيف الفيلم')\n",
    "duration=data.get(\"مدة الفيلم (دقيقة)\")\n",
    "synopses=data.get('ملخص')\n",
    "actors=data.get('تمثيل')\n",
    "author=data.get(\"تأليف\")\n",
    "producer=data.get(\"إنتاج\")\n",
    "cameraMan=data.get(\"تصوير\")\n",
    "montage=data.get(\"مونتاج\")\n",
    "decor=data.get(\"ديكور\")\n",
    "malabes=data.get(\"ملابس\")\n",
    "music=data.get(\"موسيقى\")\n",
    "director=data.get(\"إخراج\")\n",
    "distributor=data.get(\"توزيع\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaing data through some steps:**\n",
    "   - Making Morphological Disambiguation using Camel library\n",
    "   - Applying the following steps:\n",
    "        - removing punctuations\n",
    "        - removing stop words \n",
    "        - removing Arabic Diacritics (Tashkeel)\n",
    "        - removing digits\n",
    "        - removing elongation (\"ء\" -> \"ا\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import re\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ''' + string.punctuation\n",
    "\n",
    "# Arabic stop words with nltk\n",
    "stop_words= pd.read_excel(r'E:\\DataAnalysis Internship\\stop_words.xlsx')\n",
    "stop_words=stop_words.get('stop words')\n",
    "stop_words =list(stop_words)+ list(nltk.corpus.stopwords.words(\"arabic\"))\n",
    "stop_words.append('بعد')\n",
    "stop_words.append('خلال')\n",
    "stop_words.append('الرغم')\n",
    "stop_words.append('بها')\n",
    "stop_words.append('به')\n",
    "stop_words.append('بينما')\n",
    "stop_words.append('')\n",
    "stop_words.append('.')\n",
    "    \n",
    "\n",
    "arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | # Shadda\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "\n",
    "def preprocess(text):\n",
    "    \n",
    "    '''\n",
    "    text is an arabic string input\n",
    "    \n",
    "    the preprocessed text is returned\n",
    "    '''\n",
    "    \n",
    "    #remove punctuations\n",
    "    translator = str.maketrans('', '', punctuations)\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    #remove numbers\n",
    "    text = re.sub(\"[0123456789]\", '', text)\n",
    "\n",
    "    # remove Tashkeel\n",
    "    text = re.sub(arabic_diacritics, '', text)\n",
    "    \n",
    "    \n",
    "    #remove elongation\n",
    "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
    "    text = re.sub(\"ى\", \"ي\", text)\n",
    "    text = re.sub(\"ؤ\", \"ء\", text)\n",
    "    text = re.sub(\"ئ\", \"ء\", text)\n",
    "    text = re.sub(\"ة\", \"ه\", text)\n",
    "    text = re.sub(\"گ\", \"ك\", text)\n",
    "\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "\n",
    "    return text\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel_tools.morphology.database import MorphologyDB\n",
    "from camel_tools.morphology.analyzer import Analyzer\n",
    "\n",
    "from camel_tools.disambig.mle import MLEDisambiguator\n",
    "\n",
    "# instantiate the Maximum Likelihood Disambiguator\n",
    "mle = MLEDisambiguator.pretrained()\n",
    "\n",
    "def analysis (text):\n",
    "    temp=[]\n",
    "    for i in text:\n",
    "        # The disambiguator expects pre-tokenized text\n",
    "        i = simple_word_tokenize(i)\n",
    "\n",
    "        disambig = mle.disambiguate(i)\n",
    "\n",
    "        diacritized = [d.analyses[0].analysis['diac'] for d in disambig]\n",
    "        pos_tags = [d.analyses[0].analysis['pos'] for d in disambig]\n",
    "        lemmas = [d.analyses[0].analysis['lex'] for d in disambig]\n",
    "        temp.append(' '.join(lemmas))\n",
    "    return pd.Series(temp)\n",
    "# Print the combined feature values extracted above\n",
    "#for triplet in zip(diacritized, pos_tags, lemmas):\n",
    "#    print(triplet[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingData(data):\n",
    "    data = data.apply(preprocess)\n",
    "    data=analysis(list(data))\n",
    "    data = data.apply(preprocess)\n",
    "    data=analysis(list(data))\n",
    "    data = data.apply(preprocess)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "synopses=preprocessingData(synopses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "m1=(list(moviesNames))\n",
    "d1=list(date)\n",
    "c1=(list(categories))\n",
    "d2=list(duration)\n",
    "s1=(list(synopses))\n",
    "a1=(list(actors))\n",
    "a2=(list(author))\n",
    "p1=(list(producer))\n",
    "c2=(list(cameraMan))\n",
    "m2=(list(montage))\n",
    "d3=(list(decor))\n",
    "m3=(list(malabes))\n",
    "m4=(list(music))\n",
    "d4=(list(director))\n",
    "d5=(list(distributor))\n",
    "header = [\"اسم الفيلم\",\"تاريخ العرض\",\"تصنيف الفيلم\",\"مدة الفيلم (دقيقة)\",\"ملخص\",\"تمثيل\",\"تأليف\",\"إنتاج\",\"تصوير\",\"مونتاج\",\"ديكور\",\"ملابس\",\"موسيقى\",\"إخراج\",\"توزيع\"]\n",
    "data = []\n",
    "for i in range(len(synopses)) :\n",
    "    data.append([m1[i],d1[i],c1[i],d2[i],s1[i],a1[i],a2[i],p1[i],c2[i],m2[i],d3[i],m3[i],m4[i],d4[i],d5[i]])\n",
    "with open('data.csv', 'w', encoding=\"utf-8\" ,newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # write multiple rows\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
